% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/control.R
\name{optim_control}
\alias{optim_control}
\title{Optimization control parameters}
\usage{
optim_control(
  max_epochs = 2000L,
  lr_init = 0.05,
  convergence_tol = 1e-04,
  patience = 50L,
  barrier_mu = 10,
  alpha_init = 2,
  alpha_min = 1,
  use_gpu = NULL,
  device = NULL,
  dtype = "float32"
)
}
\arguments{
\item{max_epochs}{Integer. Maximum number of epochs (full passes through
all tracts). The optimizer may stop earlier if convergence is detected.
Default: 2000.}

\item{lr_init}{Numeric. Initial ADAM learning rate. Reduced automatically
via ReduceLROnPlateau when the epoch loss plateaus. Default: 0.05.}

\item{convergence_tol}{Numeric. Relative change in epoch loss below which
the optimizer considers the solution converged. Default: 1e-4.}

\item{patience}{Integer. Number of consecutive epochs with no improvement
(at minimum learning rate) before early stopping. The LR scheduler
uses \code{2 * patience} as its own patience. Default: 50.}

\item{barrier_mu}{Numeric. Strength of the log-barrier penalty that
prevents any census tract from receiving zero predicted voters.
Set to 0 to disable. Default: 10.}

\item{alpha_init}{Numeric scalar, vector of length n, or matrix [n x k].
Initial guess for alpha. A scalar is recycled to all tracts and
brackets. Default: 2.}

\item{alpha_min}{Numeric. Lower bound for alpha values. The
reparameterization becomes \code{alpha = alpha_min + softplus(theta)}.
Default: 1, which restricts decay to linear or steeper.}

\item{use_gpu}{Logical or NULL. If \code{TRUE}, use GPU (CUDA or MPS). If
\code{FALSE}, use CPU. If \code{NULL} (default), reads the package option
\code{interpElections.use_gpu} (set via \code{\link[=use_gpu]{use_gpu()}}).}

\item{device}{Character or NULL. Torch device: \code{"cuda"}, \code{"mps"}, or
\code{"cpu"}. Only used when GPU is enabled. Default: NULL (auto-detect).}

\item{dtype}{Character. Torch dtype: \code{"float32"} or \code{"float64"}. Default:
\code{"float32"}. Float32 halves memory usage with negligible precision loss.}
}
\value{
A list of class \code{"interpElections_optim_control"} with one element
per parameter.
}
\description{
Creates a control object for the SGD optimizer in \code{\link[=optimize_alpha]{optimize_alpha()}}.
All parameters have sensible defaults; override only what you need.
}
\examples{
# Default settings
optim_control()

# Use GPU with more epochs
optim_control(use_gpu = TRUE, max_epochs = 5000)

# Stricter convergence
optim_control(convergence_tol = 1e-6, patience = 100)

}
\seealso{
\code{\link[=optimize_alpha]{optimize_alpha()}}, \code{\link[=routing_control]{routing_control()}}
}
