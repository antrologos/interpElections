% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimize.R
\name{optimize_alpha}
\alias{optimize_alpha}
\title{Find optimal decay parameters (alpha) for spatial interpolation}
\usage{
optimize_alpha(
  time_matrix,
  pop_matrix,
  source_matrix,
  row_targets = NULL,
  alpha_init = NULL,
  batch_size = 500L,
  sk_iter = 15L,
  max_steps = 800L,
  lr_init = 0.05,
  use_gpu = NULL,
  device = NULL,
  dtype = "float32",
  lower_bound = 0.01,
  upper_bound = 20,
  convergence_tol = 1e-04,
  patience = 3L,
  offset = 1,
  verbose = TRUE
)
}
\arguments{
\item{time_matrix}{Numeric matrix [n x m]. Raw travel times.
Rows = target zones, columns = source points.}

\item{pop_matrix}{Numeric matrix [n x k]. Known population per zone,
with k demographic groups as columns.}

\item{source_matrix}{Numeric matrix [m x k]. Known counts at source
points (e.g., registered voters by age group).}

\item{row_targets}{Numeric vector of length n, or NULL. Target row sums
for Sinkhorn balancing. Each element specifies how much weight a zone
should attract, proportional to its share of total population. If NULL
(default), auto-computed as \code{rowSums(pop_matrix) / sum(pop_matrix) * m}.}

\item{alpha_init}{Numeric vector of length n, or a single value to be
recycled. Initial guess for alpha. Default: \code{rep(1, n)}.}

\item{batch_size}{Integer. Number of zones (rows) sampled per SGD step.
For cities with \code{n <= batch_size}, the full batch is used. Default: 500.}

\item{sk_iter}{Integer. Number of log-domain Sinkhorn iterations per
SGD step. Higher values give more accurate per-bracket transport but
increase memory usage. Default: 15.}

\item{max_steps}{Integer. Total number of SGD steps. Default: 800.}

\item{lr_init}{Numeric. Initial ADAM learning rate. Halved at steps 200,
400, and 600. Default: 0.05.}

\item{use_gpu}{Logical or NULL. If \code{TRUE}, use GPU (CUDA or MPS). If
\code{FALSE}, use CPU. If \code{NULL} (default), reads the package option
\code{interpElections.use_gpu} (set via \code{\link[=use_gpu]{use_gpu()}}).}

\item{device}{Character or NULL. Torch device: \code{"cuda"}, \code{"mps"}, or
\code{"cpu"}. Only used when GPU is enabled. Default: NULL (auto-detect).}

\item{dtype}{Character. Torch dtype: \code{"float32"} or \code{"float64"}. Default:
\code{"float32"}. Float32 halves memory usage with negligible precision loss.}

\item{lower_bound}{Numeric. Lower bound for alpha values. Default: 0.01.
Alpha is parameterized via scaled sigmoid internally, so this bound
is always satisfied smoothly without clamping.}

\item{upper_bound}{Numeric. Upper bound for alpha values. Default: 20.
Alpha is computed as \code{upper_bound * sigmoid(theta)}, so alpha is
always in \verb{(0, upper_bound)}. This prevents both corner solutions at
the lower boundary and alpha explosion at the upper end.}

\item{convergence_tol}{Numeric. Relative change in EMA loss below which
the optimizer considers the solution converged. Default: 1e-4.}

\item{patience}{Integer. Number of consecutive convergence checks (every
50 steps) that must pass before early stopping. Default: 3.}

\item{offset}{Numeric. Value added to travel times before exponentiation.
Default: 1.}

\item{verbose}{Logical. Print progress messages? Default: TRUE.}
}
\value{
A list of class \code{"interpElections_optim"} with components:
\describe{
\item{alpha}{Numeric vector. Optimal alpha values.}
\item{value}{Numeric. Objective function value at optimum.}
\item{method}{Character. Method used (e.g.,
\code{"pb_sgd_sinkhorn_cpu"}, \code{"pb_sgd_sinkhorn_cuda"}).}
\item{convergence}{Integer. 0 = success.}
\item{iterations}{Number of SGD steps taken.}
\item{elapsed}{\code{difftime} object. Wall-clock time.}
\item{message}{Character. Additional information.}
\item{history}{Numeric vector. Loss values at each step.}
\item{grad_norm_final}{Numeric. Final gradient norm.}
\item{row_targets}{Numeric vector. Row targets used for Sinkhorn.}
\item{sk_iter}{Integer. Sinkhorn iterations per step.}
\item{batch_size}{Integer. Mini-batch size used.}
}
}
\description{
Optimizes the per-zone decay parameters that minimize the squared error
between per-bracket Sinkhorn-balanced interpolated values and known
population counts. Uses Per-Bracket SGD (PB-SGD) with mini-batch sampling
and log-domain Sinkhorn inside torch autograd. Each demographic bracket
gets its own Sinkhorn transport; gradients flow through all unrolled
iterations. Works on both CPU and GPU (CUDA/MPS).
}
\details{
The optimization requires the \code{torch} R package. Install it with
\code{\link[=setup_torch]{setup_torch()}} if not already available.

Two execution paths:
\itemize{
\item \strong{CPU} (default): \code{use_gpu = FALSE} or \code{NULL}. Uses torch on CPU
device. Fast for small/medium problems (< 2000 tracts).
\item \strong{GPU}: \code{use_gpu = TRUE}. Uses CUDA or MPS. Faster for large
problems (> 2000 tracts).
}

Both paths use PB-SGD: mini-batch ADAM with per-bracket log-domain
Sinkhorn. Gradients are computed via torch autograd through the unrolled
Sinkhorn iterations. GPU memory usage is bounded by
\code{ka * min(batch_size, n) * m * bytes_per_elem * (2 + 2 * sk_iter)}.
}
\examples{
\dontrun{
tt <- matrix(c(2, 5, 3, 4, 6, 2), nrow = 2)
pop <- matrix(c(100, 200), nrow = 2)
src <- matrix(c(80, 120, 100), nrow = 3)
result <- optimize_alpha(tt, pop, src, verbose = FALSE)
result$alpha
}

}
\seealso{
\code{\link[=use_gpu]{use_gpu()}} to toggle GPU globally, \code{\link[=sinkhorn_weights]{sinkhorn_weights()}} to
build the final weight matrix, \code{\link[=sinkhorn_objective]{sinkhorn_objective()}} for the
objective function, \code{\link[=setup_torch]{setup_torch()}} to install torch.
}
