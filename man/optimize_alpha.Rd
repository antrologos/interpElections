% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/optimize.R
\name{optimize_alpha}
\alias{optimize_alpha}
\title{Find optimal decay parameters (alpha) for spatial interpolation}
\usage{
optimize_alpha(
  time_matrix,
  pop_matrix,
  source_matrix,
  row_targets = NULL,
  optim = optim_control(),
  offset = 1,
  verbose = TRUE
)
}
\arguments{
\item{time_matrix}{Numeric matrix [n x m]. Raw travel times.
Rows = target zones, columns = source points.}

\item{pop_matrix}{Numeric matrix [n x k]. Known population per zone,
with k demographic groups as columns.}

\item{source_matrix}{Numeric matrix [m x k]. Known counts at source
points (e.g., registered voters by age group).}

\item{row_targets}{Numeric vector of length n, or NULL. Target row sums
for balancing. Each element specifies how much weight a zone should
attract, proportional to its share of total population. If NULL
(default), auto-computed as \code{rowSums(pop_matrix) / sum(pop_matrix) * m}.}

\item{optim}{An \code{\link[=optim_control]{optim_control()}} object with optimization parameters
(max_epochs, lr_init, convergence_tol, patience, barrier_mu,
alpha_init, alpha_min, use_gpu, device, dtype). Default:
\code{optim_control()}.}

\item{offset}{Numeric. Value added to travel times before exponentiation
(power kernel only; ignored when \code{kernel = "exponential"}).
Default: 1.}

\item{verbose}{Logical. Print progress messages? Default: TRUE.}
}
\value{
A list of class \code{"interpElections_optim"} with components:
\describe{
\item{alpha}{Numeric matrix [n x k]. Optimal per-tract-per-bracket
decay parameters. Each row is a census tract, each column is a
demographic bracket. Inactive brackets (zero population or voters)
are filled with 1.}
\item{value}{Numeric. Poisson deviance at optimum.}
\item{loss}{Numeric. Full loss at optimum (deviance + barrier + entropy).}
\item{W}{Numeric matrix [n x m]. Column-normalized weight matrix
from the best-epoch. Use directly for interpolation
via \verb{W \\\%*\\\% data}. Column sums are approximately 1.}
\item{method}{Character. Method used (e.g.,
\code{"pb_sgd_colnorm_cpu"}, \code{"pb_sgd_colnorm_cuda"}).}
\item{convergence}{Integer. 0 = early-stopped (improvement plateau
detected); 1 = stopped at max_epochs.}
\item{epochs}{Integer. Number of epochs completed.}
\item{steps}{Integer. Total number of SGD gradient steps.}
\item{elapsed}{\code{difftime} object. Wall-clock time.}
\item{message}{Character. Additional information.}
\item{history}{Numeric vector. Full-dataset loss at each epoch.}
\item{grad_norm_final}{Numeric. Final gradient norm (theta-space).}
\item{grad_history}{Numeric vector. Gradient norm (theta-space) at
each epoch.}
\item{lr_history}{Numeric vector. Learning rate at each epoch.}
\item{kernel}{Character. Kernel used (\code{"power"} or \code{"exponential"}).}
}
}
\description{
Optimizes the per-tract-per-bracket decay parameters that minimize the
error between interpolated values and known population counts. Uses
per-bracket SGD with column normalization and log-barrier penalty inside
torch autograd. Each demographic bracket gets its own per-tract kernel;
gradients flow through all computations. Works on both CPU and GPU
(CUDA/MPS).
}
\details{
The optimization requires the \code{torch} R package. Install it with
\code{\link[=setup_torch]{setup_torch()}} if not already available.

\strong{Kernel}: Two kernel functions are available, controlled via the
\code{kernel} field in \code{\link[=optim_control]{optim_control()}}:
\itemize{
\item \strong{Power} (default): \eqn{K(t) = (t + \text{offset})^{-\alpha}}.
Classic inverse distance weighting.
\item \strong{Exponential}: \eqn{K(t) = \exp(-\alpha \cdot t)}.
Lighter tail; relative decay increases with distance. Does not use
\code{offset}.
}

\strong{Parameterization}: alpha[i,b] is reparameterized as
\code{alpha = alpha_min + softplus(theta)} with \code{theta} unconstrained,
where \code{softplus(x) = log(1 + exp(x))}. With the default
\code{alpha_min = 1} (power kernel), alpha is always at least 1
(inverse-distance decay or steeper). The exponential kernel defaults
to \code{alpha_min = 0}. Set \code{alpha_min = 0} for unconstrained
optimization (similar to legacy \code{exp(theta)}).

\strong{Epoch structure}: Each epoch is one full-data gradient step with
exact gradients (column sums require all tracts). The loss reported at
each epoch is the true loss evaluated on the full dataset.

Two execution paths:
\itemize{
\item \strong{CPU} (default): \code{use_gpu = FALSE} or \code{NULL}. Uses torch on CPU
device. Fast for small/medium problems (< 2000 tracts).
\item \strong{GPU}: \code{use_gpu = TRUE}. Uses CUDA or MPS. Faster for large
problems (> 2000 tracts).
}

GPU memory usage is bounded by
\code{2 * ka * n * m * bytes_per_elem}.
}
\examples{
\dontrun{
tt <- matrix(c(2, 5, 3, 4, 6, 2), nrow = 2)
pop <- matrix(c(100, 200), nrow = 2)
src <- matrix(c(80, 120, 100), nrow = 3)
result <- optimize_alpha(tt, pop, src, verbose = FALSE)
result$alpha

# With custom control
result <- optimize_alpha(tt, pop, src,
  optim = optim_control(use_gpu = TRUE, max_epochs = 5000),
  verbose = FALSE)
}

}
\seealso{
\code{\link[=optim_control]{optim_control()}} for tuning parameters,
\code{\link[=use_gpu]{use_gpu()}} to toggle GPU globally, \code{\link[=compute_weight_matrix]{compute_weight_matrix()}}
to rebuild the weight matrix from pre-computed alpha,
\code{\link[=setup_torch]{setup_torch()}} to install torch.
}
